<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Panagiots Dimitrakopoulos</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle;    text-align: justify;
                  text-justify: inter-word;">
                <p class="name" style="text-align: center;">
                  Panagiotis (Panos) Dimitrakopoulos
                </p>
                <p>
                I am a postdoctoral research associate at the  <a href="https://www.ed.ac.uk/">University of Edinburgh</a> working with Prof. <a href="https://vios.science/">Sotos Tsaftaris</a> and a member of the <a href="https://www.chai.ac.uk/">CHAI HUB</a>.
              </p>
                <p>Previously, I was a PhD student supervised by  <a href="https://www.cs.uoi.gr/~cnikou/">Christophoros Nikou</a> and <a href="https://geo.uniwa.gr/en/profile/sfikas-giorgos/">Giorgos Sfikas</a>
                  at the <a href="https://www.cse.uoi.gr/?lang=en">Department of Computer Science & Engineering</a> in University of Ioannina Greece.
                </p>

                <p>
                  My research focuses on building deep learning models, primarily for compuer vision problems, that can we reason about their causal knowledge and their uncertainty using Bayesian principles.
                </p>
                <!--<p>
                  My research experience and involvement in scientific projects made me familiar with the fields of text recognition/transcription,
                  as well as the applications of complex and hypercomplex neural networks. Furthermore, a keen interest in methodologies applicable to medical applications
                  has been a consistent theme throughout my research career.
                </p>-->

                <!--<p style="text-align:center;">  Contact: p.dimitrakopoulos [ a t ] uoi.gr  </p> -->
                <p style="text-align:center;font-size:x-large">
                  <a href="mailto:pdimitra@ed.ac.uk">Email</a> &nbsp;|&nbsp;
                  <a href="data/CV.pdf">CV</a> &nbsp;|&nbsp;
                  <a href="data/bio.txt">Bio</a> &nbsp;|&nbsp;
                  <a href="https://scholar.google.com/citations?user=Xz0qnGoAAAAJ&hl=el">Scholar</a> &nbsp;|&nbsp;
				          <a href="https://github.com/streetakos/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/photo_2.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/photo_2.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!--
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">

                <h2>News</h2>
                <br>
                <div class="parent">
                  <div class="child">

                    <table style="width:100%">

                      <tr>
                          <td style="width:14%"> <strong>Feb 5, 2024</strong>: </td>
                          <td style="width:85%">
                            Serving as Area Chair for <a href="https://2024.ieeeicip.org/"> ICIP 2024</a>.</td>
                      </tr>
                      <tr>
                          <td style="width:14%"> <strong>Jan 15, 2024</strong>: </td>
                          <td style="width:85%">
                            Paper was accepted by <a href="https://iclr.cc/"> ICLR 2024</a>.</td>
                      </tr>
                      <tr>
                          <td style="width:14%"> <strong>Dec 20, 2024</strong>: </td>
                          <td style="width:85%">
                            Research Project <a href="https://bessarion.gr/">"BESSARION"</a> has ended. Take a look at the final <a href="https://play.google.com/store/apps/details?id=com.comitech.bessarion&hl=en&gl=US">product</a>.                     </td>
                      </tr>
                      <tr>
                        <td style="width:14%"> <strong>Oct 8, 2024</strong>: </td>
                        <td style="width:85%"> Co-organizing <a href="https://3dcvp.uniwa.gr/#page-top"> 1st Workshop on 3D Computer Vision and Photogrammetry (3DCV)</a> in <a href="https://2023.ieeeicip.org/">ICIP 2023</a>.</td>
                      </tr>
                  </table>


                  </div>
                </div>

              </td>
            </tr>
          -->



                      <td style="padding-left: 20px;width:100%;vertical-align:middle">
                        <h2>Publications</h2>
                      </td>


          </tbody></table>




          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding-left:20px;width:25%;vertical-align:middle">
        <img src="images/INR.png" alt="clean-usnob" width="160" height="160">
      </td>

      <td style="padding:1px;width:75%;vertical-align:middle">
        <a href="https://openreview.net/forum?id=5KUiMKRebi">
          <span class="papertitle">Implicit Neural Representation Inference for Low Dimensional Bayesian Deep Learning</span>
        </a>

        <strong>Panagiotis Dimitrakopoulos</strong> <em>Giorgos Sfikas</em>, <em>Christophoros Nikou</em>
        <br>
        <em>International Conference on Learning Representations</em>, ICLR 2024
        <br>
        <a href="https://openreview.net/pdf?id=5KUiMKRebi">PDF</a>
        |
        <a class="collapsible2">Abstract</a>
        <div class="content">
        <p>
          Bayesian inference is the standard for providing full predictive distributions with well calibrated uncertainty estimates. However, scaling to a modern, overparameterized deep learning setting typically comes at the cost of severe and restrictive approximations, sacrificing model predictive strength. With our approach, we factor model parameters as a function of deterministic and probabilistic components; the model is solved by combining maximum a posteriori estimation of the former, with inference over a low-dimensional, Implicit Neural Representation of the latter. This results in a solution that combines both predictive accuracy and good calibration, as it entails inducing stochasticity over the full set of model weights while being comparatively cheap to compute. Experimentally, our approach compares favorably to the state of the art, including much more expensive methods as well as less expressive posterior approximations over full network parameters.
        </p>
        </div>
        <p></p>


      </td>
    </tr>

    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding-left:20px;width:25%;vertical-align:middle">
        <img src="images/HYPER_COMPLEX.png" alt="clean-usnob" width="160" height="160">
      </td>

      <td style="padding:1px;width:75%;vertical-align:middle">
        <a href="https://link.springer.com/chapter/10.1007/978-3-031-41685-9_13">
          <span class="papertitle">Shared-Operation Hypercomplex Networks for Handwritten Text Recognition</span>
        </a>
        <br>
        <em>G. Sfikas</em>, <em>G. Retsinas</em>, <strong>P. Dimitrakopoulos </strong> , <em>B. Gatos</em> <em>C. Nikou</em>
        <br>
        <em>International Conference on Document Analysis and Recognition</em>, ICDAR 2023
        <br>
        <a href="https://users.iit.demokritos.gr/~bgat/icdar%202023_pp200_216_LNCS%2014190.pdf">PDF</a>
        |
        <a class="collapsible2">Abstract</a>
        <div class="content">
        <p>
          Parameterized hypercomplex layers have recently emerged
as very useful alternatives of standard neural network layers. They allow
for the construction of extremely lightweight architectures, with little
to no sacrifice of accuracy. We propose networks of Shared-Operation
Parameterized Hypercomplex layers, where the operation parameteriza-
tion is co-learned by all layers in tandem. In this manner, we mitigate
the computational burden of operation parameterization, which grows
cubically with respect to the hypercomplex dimension. We attain good
word and character error rate at only a small fraction of the memory
footprint of non-hypercomplex models as well as previous non-shared
operation hypercomplex ones (up to âˆ’96.8% size reduction).
        </p>
        </div>
        <p></p>


      </td>
    </tr>


    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding-left:20px;width:25%;vertical-align:middle">
        <img src="images/VAR_FPN.png" alt="clean-usnob" width="160" height="160">
      </td>

      <td style="padding:1px;width:75%;vertical-align:middle">
        <a href="https://proceedings.mlr.press/v162/dimitrakopoulos22a.html">
          <span class="papertitle">Variational Feature Pyramid Networks</span>
        </a>
        <br>
        <strong>Panagiotis Dimitrakopoulos</strong> <em>Giorgos Sfikas</em>, <em>Christophoros Nikou</em>
        <br>
        <em>International Conference on Machine Learning</em>, ICML 2022
        <br>
        <a href="https://proceedings.mlr.press/v162/dimitrakopoulos22a/dimitrakopoulos22a.pdf">PDF</a>
        |
        <a href="https://slideslive.com/38983887/variational-feature-pyramid-networks?ref=search-presentations">Video</a>
        <!--|
        <a href="https://icml.cc/media/icml-2022/Slides/17888.pdf">Slides</a>-->
        |
        <a class="collapsible2">Abstract</a>
        <div class="content">
        <p>
          Recent architectures for object detection adopt a Feature Pyramid Network as a backbone for deep feature extraction. Many works focus on the design of pyramid networks which produce richer feature representations. In this work, we opt to learn a dataset-specific architecture for Feature Pyramid Networks. With the proposed method, the network fuses features at multiple scales, it is efficient in terms of parameters and operations, and yields better results across a variety of tasks and datasets. Starting by a complex network, we adopt Variational Inference to prune redundant connections. Our model, integrated with standard detectors, outperforms the state-of-the-art feature fusion networks.
        </p>
        </div>
        <p></p>
        <!--<p>
        A Variational Bayesian Feature Pyramid Network for accurate and efficient object detection and uncertainty estimation.
      </p> -->
      </td>
    </tr>

    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding-left:20px;width:25%;vertical-align:middle">
        <img src="images/WIND_2.png" alt="clean-usnob" width="160" height="160">
      </td>

      <td style="padding:1px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9053325/">
          <span class="papertitle">Wind: Wasserstein Inception Distance for Evaluating Generative Adversarial Network Performance</span>
        </a>
        <br>
        <strong>Panagiotis Dimitrakopoulos</strong> <em>Giorgos Sfikas</em>, <em>Christophoros Nikou</em>
        <br>
        <em> International Conference on Acoustics, Speech and Signal Processing</em>, ICASP 2020
        <br>
        <a href="https://bessarion.gr/wp-content/uploads/2020/12/icassp-FID-GMM.pdf">PDF</a>
        |
        <a href="https://github.com/streetakos/wasserstein-distance">Code</a>
        |
        <a class="collapsible2">Abstract</a>
        <div class="content">
        <p>
          In this paper, we present Wasserstein Inception Distance (WInD), a novel metric for evaluating performance of Generative Adversarial Networks (GANs). The proposed metric extends on the rationale of the previously proposed Frechet Inception Distance (FID), in the sense that GAN performance is quantified in terms of data and model distribution divergence. We extend FID by relaxing the Gaussian hypothesis of the related inception features and extend it for non-Gaussian, multimodal distributions. Gaussian Mixture Models (GMMs) are used to model data and model inception features, and the Wasserstein distance is employed as a pdf matching metric. We show that the proposed WInD metric inherits the desirable features of FID and correlates well with actual GAN performance. Furthermore, WInD can correctly evaluate cases were data and model distribution erroneously would appear as well peforming using FID. Numerical experiments on synthetic and real datasets validate our claim.
        </p>
        </div>

      </td>
    </tr>


    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding-left:20px;width:25%;vertical-align:middle">
        <img src="images/ISNIG_GAN.png" alt="clean-usnob" width="160" height="160">
      </td>

      <td style="padding:1px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9098618">
          <span class="papertitle">ISING-GAN: Annotated Data Augmentation with a Spatially Constrained Generative Adversarial Network</span>
        </a>
        <br>
        <strong>Panagiotis Dimitrakopoulos</strong> <em>Giorgos Sfikas</em>, <em>Christophoros Nikou</em>
        <br>
        <em>International Symposium on Biomedical Imaging</em>, ISBI 2020
        <br>
        <a href="https://www.cse.uoi.gr/~cnikou/Publications/C077%20-%20Dimitrakopoulos%20-%20isbi%202020%20-%20Iowa%20City.pdf">PDF</a>
        |
        <a class="collapsible2">Abstract</a>
        <div class="content">
        <p>
          Data augmentation is a popular technique with which new dataset samples are artificially synthesized to the end of assisting training of learning-based algorithms and avoiding overfitting. Methods based on generative adversarial networks (GANs) have recently rekindled interest in research on new techniques for data augmentation. With the current paper we propose a new GAN-based model for data augmentation, comprising a suitable Markov random field-based spatial constraint that encourages synthesis of spatially smooth outputs. Oriented towards use with medical imaging sets where a localization/segmentation annotation is available, our model can simultaneously also produce artificial annotations. We gauge performance numerically by measuring performance through U-Net trained to detect cells on microscopy images, by taking into account the produced augmented dataset. Numerical trials, as well as qualitative results validate the contribution of our model.
        </p>
        </div>

      </td>
    </tr>

    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding-left:20px;width:25%;vertical-align:middle">
        <img src="images/BIBE2.png" alt="clean-usnob" width="160" height="160">
      </td>

      <td style="padding:1px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/8941655/">
          <span class="papertitle"> Nuclei Detection Using Residual Attention Feature Pyramid Networks</span>
        </a>
        <br>
        <strong>Panagiotis Dimitrakopoulos</strong> <em>Giorgos Sfikas</em>, <em>Christophoros Nikou</em>
        <br>
        <em>International Conference on Bioinformatics and Bioengineering</em>, BIBE 2019
        <br>
        <em style="color:#FA8072;"> Best Student Paper Award</em>  <!--<p>
        A Variational Bayesian Feature Pyramid Network for accurate and efficient object detection and uncertainty estimation.  ff337a
      </p> -->
        <br>
        <a href="https://www.cse.uoi.gr/~sfikas/attention.pdf">PDF</a>
        |
        <a class="collapsible2">Abstract</a>
        <div class="content">
        <p>
          Detection of cell nuclei in microscopy images is a challenging research topic due to limitations in acquired image quality as well as due to the diversity of nuclear morphology. This has been a topic of enduring interest with promising success shown by deep learning methods. Recently, attention gating methods have been proposed and employed successfully in a diverse array of pattern recognition tasks. In this work, we introduce a novel attention module and integrate it with feature pyramid networks and the state-of-the-art Mask R-CNN network. We show with numerical experiments that the proposed model outperforms the state-of-the-art baseline.
        </p>
        </div>
      </td>
    </tr>

    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding-left:20px;width:25%;vertical-align:middle">
        <img src="images/SIPAKMED.png" alt="clean-usnob" width="160" height="160">
      </td>

      <td style="padding:1px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/8451588">
          <span class="papertitle"> SIPAKMED: A New Dataset for Feature and Image Based Classification of Normal and Pathological Cervical Cells in Pap Smear Images </span>
        </a>
        <br>
        <em>M.E. Plissiti </em> <strong>P. Dimitrakopoulos</strong>,  <em>G. Sfikas </em>  <em>C. Nikou</em>, <em>O. Krikoni</em>, <em>A. Charchanti</em>
        <br>
        <em>International Conference on Image Processing</em>, ICIP 2018
        <br>
        <a href="https://www.cs.uoi.gr/~sfikas/sipakmed2018.pdf">PDF</a>
        |
        <a href="https://www.cs.uoi.gr/~marina/sipakmed.html">Project Page</a>
        |
        <a class="collapsible2">Abstract</a>
        <div class="content">
        <p>
          Classification of cervical cells in Pap smear images is a challenging task due to the limitations these images exhibit and the complexity of the morphological changes in the structural parts of the cells. This procedure is very important as it provides fundamental information for the detection of cancerous or precancerous lesions. For this reason several algorithms have been proposed in order to classify normal and abnormal cells in such images. However, it is a common phenomenon that each research group usually creates its own dataset of images, as well-established datasets are not publicly available. To overcome this obstacle and to assist the research progress in this field, we present an annotated image database of Pap smear images, in which the cells are categorized in five different classes, depending on their cytomorphological features. The area of the cytoplasm and the nucleus in each image is manually defined by experts and salient features of intensity, texture and shape are calculated for each region of interest. Several experiments have been performed for the classification of these images and they include feature and image based classification schemes. In this direction, methods based on support vector machines and deep neural networks are tested and the performance of each classifier is presented in order to constitute a reference point for the evaluation of future classification techniques.
        </p>
        </div>
      </td>
    </tr>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Template adapted from <a href="https://github.com/jonbarron/website">John Barron's website.</a>.

                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>

    <script>
    var coll = document.getElementsByClassName("collapsible2");
    var i;

    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
          content.style.display = "none";
        } else {
          content.style.display = "block";
        }
      });
    }
</script>

  </body>
</html>
